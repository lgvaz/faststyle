{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.basics import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.callback.all import *\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from faststyle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_feat_model(m):\n",
    "  m = m.to(default_device()).eval()\n",
    "  for p in m.parameters(): p.requires_grad=False\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_layers(m, idxs):\n",
    "  return [m[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_imagenet_norm = NormalizeAll.from_stats(*imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FeatModels:\n",
    "  @staticmethod\n",
    "  def vgg16():\n",
    "    m = prepare_feat_model(vgg16(True).features)\n",
    "    stl_ls = get_layers(m, (1, 11, 18, 25))\n",
    "    cnt_ls = get_layers(m, (20,))\n",
    "    return dict(m=m, stl_ls=stl_ls, cnt_ls=cnt_ls, tfms=[_imagenet_norm])\n",
    "  \n",
    "  @staticmethod\n",
    "  def vgg19():\n",
    "    m = prepare_feat_model(vgg19(True).features)\n",
    "    stl_ls = get_layers(m, (1, 6, 11, 20, 29))\n",
    "    cnt_ls = get_layers(m, (22,))\n",
    "    return dict(m=m, stl_ls=stl_ls, cnt_ls=cnt_ls, tfms=[_imagenet_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LayerFeats(Module):\n",
    "  def __init__(self, m, stl_ls, cnt_ls, tfms=None):\n",
    "    self.m, self.tfms = m, Pipeline(tfms)\n",
    "    self.stl_hooks = hook_outputs(stl_ls, detach=False)\n",
    "    self.cnt_hooks = hook_outputs(cnt_ls, detach=False)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    _ = self.m(self.tfms(x))\n",
    "    return self.stl_hooks.stored, self.cnt_hooks.stored\n",
    "  \n",
    "  @classmethod\n",
    "  def from_feat_m(cls, feat_m): return cls(**feat_m())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "get_feats = LayerFeats.from_feat_m(FeatModels.vgg19)\n",
    "tim = TensorImage.create('../examples/styles/abstract.jpg')\n",
    "stl_fts,cnt_fts = get_feats(tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(stl_fts), 5)\n",
    "test_eq(len(cnt_fts), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_layer_features.ipynb.\n",
      "Converted 03_loss.ipynb.\n",
      "Converted 04_learner.ipynb.\n",
      "Converted 04_models.ipynb.\n",
      "Converted 06_callback.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
