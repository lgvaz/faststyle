# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_loss.ipynb (unless otherwise specified).

__all__ = ['gram', 'feat_m', 'VggFeats', 'layers', 'get_fs', 'get_stl_fs', 'get_cnt_fs', 'cnt_loss_fn',
           'get_style_loss_fn', 'tv_loss_fn', 'FSTLoss', 'FastStyleLoss', 'StyleLoss', 'ContentLoss', 'TVLoss',
           'FastStyleLoss2']

# Cell
from fastai2.basics import *
from fastai2.vision.all import *
from fastai2.callback.all import *
from torchvision.models import vgg16, vgg19
from faststyle import *

# Cell
def gram(x):
    n,c,h,w = x.size()
    x = x.view(n, c, -1)
    return (x @ x.transpose(1,2))/(c*h*w)

# Cell
#TODO: hardcoded model
feat_m = vgg19(True).features.cuda().eval()
for p in feat_m.parameters(): p.requires_grad=False

# Cell
def VggFeats(layers):
  hooks = hook_outputs(layers, detach=False)
  def _inner(x):
    feat_m(x)
    return hooks.stored
  return _inner

# Cell
#TODO: hardcoded layers
# layers = [feat_m[i] for i in [1, 11, 18, 25, 20]]; layers # vgg16
layers = [feat_m[i] for i in [1, 6, 11, 20, 29, 22]]; layers # vgg19
get_fs = VggFeats(layers)

# Cell
#TODO: hardcoded layers
def get_stl_fs(fs): return fs[:-1]
def get_cnt_fs(fs): return fs[-1:]

# Cell
def cnt_loss_fn(fs, y_fs):
  return sum([F.mse_loss(*o) for o in zip(*map(get_cnt_fs, [fs,y_fs]))])

# Cell
#TODO: hardcoded stl_loss_mult
def get_style_loss_fn(style_tims):
  stl_fs = [get_fs(im) for im in style_tims]
  # TODO: Weighted mean
  stl_grams = [torch.stack([gram(x) for x in stl_t]).mean(axis=0) for stl_t in zip(*stl_fs)]
  def stl_loss_fn(fs, y_fs):
    bs = fs[0].shape[0]
    stl_losses = [F.mse_loss(y_gram.repeat(bs,1,1),gram(f)) for y_gram,f in zip(*map(get_stl_fs, [stl_grams, fs]))]
    return sum(stl_losses)
  return stl_loss_fn

# Cell
#TODO: hardcoded tv_loss_mult
def tv_loss_fn(img):
  tv_h = ((img[:,:,1:,:] - img[:,:,:-1,:]).pow(2)).mean()
  tv_w = ((img[:,:,:,1:] - img[:,:,:,:-1]).pow(2)).mean()
  return (tv_h + tv_w)

# Cell
#TODO: Use @func_kwargs
class FSTLoss(Module):
  def __init__(self, get_fs, stl_loss_fn, cnt_loss_fn, tv_loss_fn,
               stl_loss_w=3e5, cnt_loss_w=1, tv_loss_w=20):
    store_attr(self, 'get_fs,stl_loss_fn,cnt_loss_fn,tv_loss_fn')
    store_attr(self, 'stl_loss_w,cnt_loss_w,tv_loss_w')
    self.metric_names = ['stl', 'cnt', 'tv']

  def forward(self, pred, targ, **kwargs):
    pred_feats,targ_feats = self.get_fs(pred),self.get_fs(targ)
    assert not (pred_feats[0] == targ_feats[0]).all()
    self.stl = self.stl_loss_fn(pred_feats, targ_feats)
    self.cnt = self.cnt_loss_fn(pred_feats, targ_feats)
    self.tv  = self.tv_loss_fn (pred)
    return self.stl_loss_w*self.stl+self.cnt_loss_w*self.cnt+self.tv_loss_w*self.tv

# Cell
def _get_ims(fns):
  t = TfmdLists(fns, tfms=[PILImage.create, ToTensor(), IntToFloatTensor(),
                               Normalize.from_stats(*coco_stats, cuda=False)])
  return [o.to(default_device()) for o in t]

# Cell
def FastStyleLoss(style_fns, **kwargs):
  stl_loss_fn = get_style_loss_fn(_get_ims(style_fns))
  return FSTLoss(get_fs, stl_loss_fn, cnt_loss_fn, tv_loss_fn)

# Cell
def StyleLoss():
  def _inner(fs, y_fs, sims_fs):
    bs = fs[0].shape[0]
    #TODO: don't forget get_stl_fs
    sims_gs = get_stl_fs([torch.stack([gram(x) for x in stl_t]).mean(axis=0) for stl_t in zip(*sims_fs)])
    pred_gs = get_stl_fs([gram(f) for f in fs])
    assert len(sims_gs) == len(pred_gs)
    stl_losses = [F.mse_loss(g1.repeat(bs,1,1),g2) for g1,g2 in zip(sims_gs,pred_gs)]
    return sum(stl_losses)
  return _inner

# Cell
def ContentLoss():
  def _inner(fs, y_fs, sims_fs):
    return sum([F.mse_loss(*o) for o in zip(*map(get_cnt_fs, [fs,y_fs]))])
  return _inner

# Cell
def TVLoss():
  def _inner(img):
    tv_h = ((img[:,:,1:,:] - img[:,:,:-1,:]).pow(2)).mean()
    tv_w = ((img[:,:,:,1:] - img[:,:,:,:-1]).pow(2)).mean()
    return (tv_h + tv_w)
  return _inner

# Cell
#TODO: Use @func_kwargs
class FastStyleLoss2(Module):
  def __init__(self, get_fs, stl_loss_w=3e5, cnt_loss_w=1, tv_loss_w=20):
    self.stl_loss_fn = StyleLoss()
    self.cnt_loss_fn = ContentLoss()
    self.tv_loss_fn  = TVLoss()
    store_attr(self, 'get_fs,stl_loss_w,cnt_loss_w,tv_loss_w')
    self.metric_names = ['stl', 'cnt', 'tv']

  def forward(self, pred, targ, sims_fs, **kwargs):
    pred_feats,targ_feats = self.get_fs(pred),self.get_fs(targ)
    assert not (pred_feats[0] == targ_feats[0]).all()
    self.stl = self.stl_loss_w*self.stl_loss_fn(pred_feats, targ_feats, sims_fs)
    self.cnt = self.cnt_loss_w*self.cnt_loss_fn(pred_feats, targ_feats, sims_fs)
    self.tv  = self.tv_loss_w *self.tv_loss_fn (pred)
    return self.stl+self.cnt+self.tv